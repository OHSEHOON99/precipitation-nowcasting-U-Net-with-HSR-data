{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Testing and Performance Evaluation**\n",
    "\n",
    "This notebook tests four pre-trained models (**UNet**, **SEUNet**, **AttUNet**, **DualAttUNet**) on a given test dataset and evaluates their performance using various metrics. The results are saved in an Excel file with highlighted best and second-best values for each metric.\n",
    "\n",
    "## **Steps**\n",
    "\n",
    "1. **Configuration**\n",
    "   - Device setup (CPU or GPU)\n",
    "   - Batch size: 4\n",
    "   - Test dataset path and result save path\n",
    "   - Sequence length for evaluation\n",
    "\n",
    "2. **Model and Weights**\n",
    "   - Four models are loaded:\n",
    "     - UNet\n",
    "     - SEUNet\n",
    "     - AttUNet\n",
    "     - DualAttUNet\n",
    "   - Corresponding pre-trained weights are provided for each model.\n",
    "\n",
    "3. **Metrics**\n",
    "   - The following metrics are computed:\n",
    "     - **FAR (False Alarm Rate)**\n",
    "     - **CSI (Critical Success Index)**\n",
    "     - **HSS (Heidke Skill Score)**\n",
    "     - **GSS (Gilbert Skill Score)**\n",
    "     - **MSE (Mean Squared Error)**\n",
    "     - **MAE (Mean Absolute Error)**\n",
    "   - These metrics are evaluated at different rainfall intensity thresholds:  \n",
    "     `>0.5, >2, >5, >10, >30`\n",
    "\n",
    "4. **Results**\n",
    "   - The computed metrics are saved in an Excel file.\n",
    "   - The Excel file highlights:\n",
    "     - **Lowest FAR values** (best and second-best) for each threshold.\n",
    "     - **Highest CSI, HSS, GSS values** (best and second-best) for each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "\n",
    "from models import UNet, SEUNet, DualAttUNet, AttUNet  # Import only necessary models\n",
    "from evaluate import Evaluater\n",
    "from TSDataset import TSDataset, ToTensor\n",
    "from utils import *  # Import utility functions\n",
    "from openpyxl.styles import Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3195575/2371503531.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Testing UNet: 100%|██████████| 229/229 [00:07<00:00, 28.71batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     14819530 |      4582195 |      1164645 |       231686 |        12070\n",
      "INFO:root:      Precision |       0.9274 |       0.8635 |       0.7919 |       0.7334 |       0.6729\n",
      "INFO:root:         Recall |       0.8904 |       0.8524 |       0.7722 |       0.6453 |       0.4148\n",
      "INFO:root:       F1 Score |       0.9085 |       0.8579 |       0.7819 |       0.6865 |       0.5132\n",
      "INFO:root:            FAR |       0.0726 |       0.1365 |       0.2081 |       0.2666 |       0.3271\n",
      "INFO:root:            CSI |       0.8324 |       0.7512 |       0.6419 |       0.5226 |       0.3452\n",
      "INFO:root:            GSS |       0.7766 |       0.7301 |       0.6345 |       0.5206 |       0.3450\n",
      "INFO:root:            HSS |       0.8743 |       0.8440 |       0.7763 |       0.6847 |       0.5130\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |       0.0015\n",
      "INFO:root:            MAE |       0.0082\n",
      "/tmp/ipykernel_3195575/2371503531.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Testing SEUNet: 100%|██████████| 229/229 [00:07<00:00, 31.74batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     15100372 |      4736208 |      1235311 |       237937 |        10797\n",
      "INFO:root:      Precision |       0.9144 |       0.8435 |       0.7663 |       0.7256 |       0.7248\n",
      "INFO:root:         Recall |       0.9073 |       0.8810 |       0.8190 |       0.6627 |       0.3710\n",
      "INFO:root:       F1 Score |       0.9108 |       0.8618 |       0.7918 |       0.6927 |       0.4908\n",
      "INFO:root:            FAR |       0.0856 |       0.1565 |       0.2337 |       0.2744 |       0.2752\n",
      "INFO:root:            CSI |       0.8363 |       0.7572 |       0.6553 |       0.5299 |       0.3252\n",
      "INFO:root:            GSS |       0.7804 |       0.7359 |       0.6477 |       0.5278 |       0.3251\n",
      "INFO:root:            HSS |       0.8767 |       0.8479 |       0.7862 |       0.6909 |       0.4906\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |       0.0016\n",
      "INFO:root:            MAE |       0.0079\n",
      "Testing AttUNet: 100%|██████████| 229/229 [00:08<00:00, 27.73batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     15043809 |      4742076 |      1262502 |       262053 |        14785\n",
      "INFO:root:      Precision |       0.9144 |       0.8274 |       0.7236 |       0.6484 |       0.5796\n",
      "INFO:root:         Recall |       0.9039 |       0.8821 |       0.8370 |       0.7298 |       0.5081\n",
      "INFO:root:       F1 Score |       0.9091 |       0.8539 |       0.7762 |       0.6867 |       0.5415\n",
      "INFO:root:            FAR |       0.0856 |       0.1726 |       0.2764 |       0.3516 |       0.4204\n",
      "INFO:root:            CSI |       0.8334 |       0.7450 |       0.6342 |       0.5229 |       0.3713\n",
      "INFO:root:            GSS |       0.7768 |       0.7226 |       0.6260 |       0.5205 |       0.3711\n",
      "INFO:root:            HSS |       0.8744 |       0.8389 |       0.7700 |       0.6847 |       0.5413\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |       0.0016\n",
      "INFO:root:            MAE |       0.0081\n",
      "Testing DualAttUNet: 100%|██████████| 229/229 [00:08<00:00, 28.53batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     14977547 |      4648383 |      1198353 |       232411 |        12976\n",
      "INFO:root:      Precision |       0.9207 |       0.8559 |       0.7794 |       0.7351 |       0.6541\n",
      "INFO:root:         Recall |       0.8999 |       0.8647 |       0.7945 |       0.6473 |       0.4459\n",
      "INFO:root:       F1 Score |       0.9102 |       0.8603 |       0.7869 |       0.6884 |       0.5303\n",
      "INFO:root:            FAR |       0.0793 |       0.1441 |       0.2206 |       0.2649 |       0.3459\n",
      "INFO:root:            CSI |       0.8352 |       0.7548 |       0.6486 |       0.5249 |       0.3608\n",
      "INFO:root:            GSS |       0.7796 |       0.7337 |       0.6411 |       0.5228 |       0.3607\n",
      "INFO:root:            HSS |       0.8761 |       0.8464 |       0.7813 |       0.6867 |       0.5301\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |       0.0016\n",
      "INFO:root:            MAE |       0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at /home/sehoon/Desktop/측량학회/performance_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "amp = False  # Enable or disable Automatic Mixed Precision (AMP)\n",
    "batch_size = 4  # Batch size\n",
    "save_dir = '/home/sehoon/Desktop/측량학회/single_model_results'  # Directory to save results\n",
    "test_data_path = \"/home/sehoon/Desktop/측량학회/data/dataset_0.5_0.05_6_1_1/test/\"  # Path to the test dataset\n",
    "evaluater_seq_len = 1  # Sequence length for the Evaluater class\n",
    "\n",
    "# List of pre-trained models and their corresponding weight paths\n",
    "models = [\n",
    "    ('UNet', UNet(n_channels=6, n_classes=1)),\n",
    "    ('SEUNet', SEUNet(n_channels=6, n_classes=1)),\n",
    "    ('AttUNet', AttUNet(n_channels=6, n_classes=1)),\n",
    "    ('DualAttUNet', DualAttUNet(n_channels=6, n_classes=1))\n",
    "]\n",
    "\n",
    "model_paths = [\n",
    "    \"/home/sehoon/Desktop/측량학회/results/UNet_epochs=100_bs=4_lr=0.0001_20240922_173646_final_model.pth\",\n",
    "    ...\n",
    "]\n",
    "\n",
    "# Function to test models and save results\n",
    "def test_model_and_save_results(model, test_data_path, device, amp_enabled, batch_size, model_name, evaluater_seq_len):\n",
    "    test_set = TSDataset(Path(test_data_path), transform=ToTensor())\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=(device.type == 'cuda'))\n",
    "    \n",
    "    evaluater = Evaluater(seq_len=evaluater_seq_len)\n",
    "\n",
    "    # Model testing\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Testing {model_name}\", unit=\"batch\"):\n",
    "            inputs, targets = batch['input'].to(device), batch['label'].to(device)\n",
    "            with torch.amp.autocast('cuda', enabled=amp_enabled):\n",
    "                predictions = model(inputs)\n",
    "            evaluater.update(gt=targets.cpu().numpy(), pred=predictions.cpu().numpy())\n",
    "    \n",
    "    # Extract performance metrics (FAR, CSI, HSS, GSS)\n",
    "    precision, recall, f1, far, csi, hss, gss, mse, mae = evaluater.print_stat_readable()\n",
    "    return far, csi, hss, gss, mse, mae\n",
    "\n",
    "# Define the structure of the dictionary to store results for each metric\n",
    "performance_results = {\n",
    "    'FAR': {\">0.5\": [], \">2\": [], \">5\": [], \">10\": [], \">30\": []},\n",
    "    'CSI': {\">0.5\": [], \">2\": [], \">5\": [], \">10\": [], \">30\": []},\n",
    "    'HSS': {\">0.5\": [], \">2\": [], \">5\": [], \">10\": [], \">30\": []},\n",
    "    'GSS': {\">0.5\": [], \">2\": [], \">5\": [], \">10\": [], \">30\": []}\n",
    "}\n",
    "\n",
    "model_names = [\"UNet\", \"SEUNet\", \"AttUNet\", \"DualAttUNet\"]\n",
    "\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "\n",
    "# Extract performance metrics for each model and save results\n",
    "for (model_name, model), model_path in zip(models, model_paths):\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Test the model and extract FAR, CSI, HSS, and GSS values\n",
    "    far, csi, hss, gss, mse, mae = test_model_and_save_results(\n",
    "        model=model,\n",
    "        test_data_path=test_data_path,\n",
    "        device=device,\n",
    "        amp_enabled=amp,\n",
    "        batch_size=batch_size,\n",
    "        model_name=model_name,\n",
    "        evaluater_seq_len=evaluater_seq_len\n",
    "    )\n",
    "\n",
    "    performance_results['FAR'][\">0.5\"].append(far[0, 0])\n",
    "    performance_results['FAR'][\">2\"].append(far[0, 1])\n",
    "    performance_results['FAR'][\">5\"].append(far[0, 2])\n",
    "    performance_results['FAR'][\">10\"].append(far[0, 3])\n",
    "    performance_results['FAR'][\">30\"].append(far[0, 4])\n",
    "\n",
    "    performance_results['CSI'][\">0.5\"].append(csi[0, 0])\n",
    "    performance_results['CSI'][\">2\"].append(csi[0, 1])\n",
    "    performance_results['CSI'][\">5\"].append(csi[0, 2])\n",
    "    performance_results['CSI'][\">10\"].append(csi[0, 3])\n",
    "    performance_results['CSI'][\">30\"].append(csi[0, 4])\n",
    "\n",
    "    performance_results['HSS'][\">0.5\"].append(hss[0, 0])\n",
    "    performance_results['HSS'][\">2\"].append(hss[0, 1])\n",
    "    performance_results['HSS'][\">5\"].append(hss[0, 2])\n",
    "    performance_results['HSS'][\">10\"].append(hss[0, 3])\n",
    "    performance_results['HSS'][\">30\"].append(hss[0, 4])\n",
    "\n",
    "    performance_results['GSS'][\">0.5\"].append(gss[0, 0])\n",
    "    performance_results['GSS'][\">2\"].append(gss[0, 1])\n",
    "    performance_results['GSS'][\">5\"].append(gss[0, 2])\n",
    "    performance_results['GSS'][\">10\"].append(gss[0, 3])\n",
    "    performance_results['GSS'][\">30\"].append(gss[0, 4])\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "# Save results to an Excel file and apply formatting\n",
    "save_path = \"/home/sehoon/Desktop/측량학회/performance_results.xlsx\"\n",
    "with pd.ExcelWriter(save_path, engine='openpyxl') as writer:\n",
    "    for metric in ['FAR', 'CSI', 'HSS', 'GSS']:\n",
    "        # Convert results for each metric to a DataFrame\n",
    "        metric_df = pd.DataFrame(performance_results[metric], index=model_names)\n",
    "        \n",
    "        # Save to Excel\n",
    "        metric_df.to_excel(writer, sheet_name=f'{metric} Results')\n",
    "        worksheet = writer.sheets[f'{metric} Results']\n",
    "\n",
    "        # Apply styling for the smallest and second smallest values for each threshold\n",
    "        for col in range(2, len(metric_df.columns) + 2):  # The first column is the index (model names), values start from the second column\n",
    "            values = [metric_df.iloc[row, col - 2] for row in range(len(metric_df))]\n",
    "\n",
    "            if metric == 'FAR':\n",
    "                # For FAR, find the lowest and second lowest values\n",
    "                min_idx = np.argmin(values)\n",
    "                second_min_idx = np.argsort(values)[1]\n",
    "\n",
    "                # Apply bold font to the lowest value\n",
    "                worksheet.cell(row=min_idx + 2, column=col).font = Font(bold=True)\n",
    "\n",
    "                # Apply underline to the second lowest value\n",
    "                worksheet.cell(row=second_min_idx + 2, column=col).font = Font(underline=\"single\")\n",
    "\n",
    "            else:\n",
    "                # For other metrics (CSI, HSS, GSS), apply styling to the highest values\n",
    "                max_idx = np.argmax(values)\n",
    "                second_max_idx = np.argsort(values)[-2]\n",
    "\n",
    "                # Apply bold font to the highest value\n",
    "                worksheet.cell(row=max_idx + 2, column=col).font = Font(bold=True)\n",
    "\n",
    "                # Apply underline to the second highest value\n",
    "                worksheet.cell(row=second_max_idx + 2, column=col).font = Font(underline=\"single\")\n",
    "\n",
    "print(f\"Results saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten and scale\n",
    "mse_values = np.array([item.flatten()[0] for item in mse_list]) * 20000\n",
    "mae_values = np.array([item.flatten()[0] for item in mae_list]) * 20000\n",
    "\n",
    "# Append new values using np.append\n",
    "mse_values = np.append(mse_values, 0.00148414936847985 * 20000)\n",
    "mae_values = np.append(mae_values, 0.00775704858824611 * 20000)\n",
    "\n",
    "# 모델 이름 설정\n",
    "models = [\"U-Net\", \"SE U-Net\", \"Attention U-Net\", \"Dual Attention U-Net\", \"Ensemble\"]\n",
    "\n",
    "# 바의 위치 설정\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# 바의 너비 설정\n",
    "width = 0.35\n",
    "\n",
    "# 서브플롯 생성 (1행 2열)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 첫 번째 서브플롯: MSE 차트\n",
    "ax1.bar(x, mse_values, width, label='MSE', color='skyblue')\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.set_title('MSE')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models)\n",
    "ax1.legend()\n",
    "\n",
    "# 두 번째 서브플롯: MAE 차트\n",
    "ax2.bar(x, mae_values, width, label='MAE', color='salmon')\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.set_title('MAE')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(models)\n",
    "ax2.legend()\n",
    "\n",
    "# 플롯 간 간격 조정\n",
    "plt.tight_layout()\n",
    "\n",
    "# 플롯 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 이름 설정\n",
    "models = [\"U-Net\", \"SE U-Net\", \"Attention U-Net\", \"Dual Attention U-Net\", \"Ensemble\"]\n",
    "\n",
    "# Flatten and scale (assuming mse_list and mae_list are predefined)\n",
    "mse_values = np.array([item.flatten()[0] for item in mse_list]) * 20000\n",
    "mae_values = np.array([item.flatten()[0] for item in mae_list]) * 20000\n",
    "\n",
    "# Append new values using np.append\n",
    "mse_values = np.append(mse_values, 0.00148414936847985 * 20000)\n",
    "mae_values = np.append(mae_values, 0.00775704858824611 * 20000)\n",
    "\n",
    "# Create a DataFrame with the values\n",
    "df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'MSE': mse_values,\n",
    "    'MAE': mae_values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Weighted Average Ensemble and Grid Search for Parameter Tuning**\n",
    "\n",
    "In this study, a **weighted average ensemble** approach is used to combine the predictions from multiple models. The goal is to improve the overall performance by leveraging the strengths of different models. Additionally, **grid search** is employed to determine the optimal combination of weights for each model in the ensemble.\n",
    "\n",
    "The best combination of weights is determined based on the performance metrics, and the results are saved in an Excel file. The following steps summarize the workflow:\n",
    "1. Load pre-trained models and their weights.\n",
    "2. Apply grid search to find the optimal set of weights.\n",
    "3. Evaluate the ensemble performance using different metrics.\n",
    "4. Save the results, including the optimal weights and corresponding performance, to an Excel file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2850879/964264031.py:211: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)  # 전체 모델 로드\n",
      "Testing Ensemble: 100%|██████████| 229/229 [06:15<00:00,  1.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble results saved in /home/sehoon/Desktop/측량학회/visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def save_image(tensor, path):\n",
    "    \"\"\"\n",
    "    Function to save a tensor as an image.\n",
    "    \"\"\"\n",
    "    image = tensor.cpu().numpy()\n",
    "    image = np.squeeze(image)  # Remove the channel dimension\n",
    "    image = (image * 255).astype(np.uint8)  # Convert values in range 0-1 to 0-255\n",
    "    Image.fromarray(image).save(path)\n",
    "\n",
    "\n",
    "def visualize_and_save(inputs, targets, model_outputs, ensemble_predictions, input_names, pred_image_name, save_dir):\n",
    "    \"\"\"\n",
    "    Function to visualize and save results as PNG images.\n",
    "\n",
    "    Parameters:\n",
    "        inputs: Model input image tensor (including batch size, 6 time steps)\n",
    "        targets: Ground truth image tensor (including batch size)\n",
    "        model_outputs: List of predicted images from each model (including batch size)\n",
    "        ensemble_predictions: Tensor of ensemble prediction results (including batch size)\n",
    "        input_names: List of input image filenames\n",
    "        pred_image_name: Filename for prediction images\n",
    "        save_dir: Directory to save the visualization results\n",
    "    \"\"\"\n",
    "    batch_size = inputs.size(0)  # Get batch size\n",
    "    n_channels = inputs.size(1)  # Get number of time steps (input images, here 6)\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        fig, axes = plt.subplots(4, 6, figsize=(24, 16))  # 4x6 layout\n",
    "\n",
    "        # Convert data to rainfall rate\n",
    "        inputs_rainfall = dBZ_to_rfrate(pixel_to_dBZ(inputs[b].cpu().numpy()))\n",
    "        targets_rainfall = dBZ_to_rfrate(pixel_to_dBZ(targets[b].cpu().numpy()))\n",
    "        model_outputs_rainfall = [dBZ_to_rfrate(pixel_to_dBZ(model_output[b].cpu().numpy())) for model_output in model_outputs]\n",
    "        ensemble_rainfall = dBZ_to_rfrate(pixel_to_dBZ(ensemble_predictions[b].cpu().numpy()))\n",
    "\n",
    "        # Set maximum value for visualization\n",
    "        max_value = max(\n",
    "            inputs_rainfall.max(),\n",
    "            targets_rainfall.max(),\n",
    "            max([output.max() for output in model_outputs_rainfall]),\n",
    "            ensemble_rainfall.max()\n",
    "        )\n",
    "\n",
    "        # 1. Visualize input images (6 time steps)\n",
    "        for i in range(n_channels):  # C represents time step images\n",
    "            im = axes[0, i].imshow(inputs_rainfall[i, :, :], cmap='jet', vmin=0, vmax=max_value)\n",
    "            axes[0, i].set_title(f\"Input {i+1}\")\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "        # 2. Visualize target images\n",
    "        im = axes[1, 0].imshow(targets_rainfall[0, :, :], cmap='jet', vmin=0, vmax=max_value)\n",
    "        axes[1, 0].set_title(\"Target\")\n",
    "        axes[1, 0].axis('off')\n",
    "\n",
    "        # Hide remaining plots (target is visualized only once, so remaining 5 plots are disabled)\n",
    "        for i in range(1, 6):\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "        # 3. Visualize model prediction results (4 models)\n",
    "        for i, output_rainfall in enumerate(model_outputs_rainfall):\n",
    "            im = axes[2, i].imshow(output_rainfall[0, :, :], cmap='jet', vmin=0, vmax=max_value)  # Model prediction results\n",
    "            axes[2, i].set_title(f\"Model {i + 1} Prediction\")\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "        # Hide remaining plots (only 4 model predictions are visualized, so remaining 2 plots are disabled)\n",
    "        for i in range(4, 6):\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "        # 4. Visualize ensemble prediction results\n",
    "        im = axes[3, 0].imshow(ensemble_rainfall[0, :, :], cmap='jet', vmin=0, vmax=max_value)\n",
    "        axes[3, 0].set_title(\"Ensemble Prediction\")\n",
    "        axes[3, 0].axis('off')\n",
    "\n",
    "        # Hide remaining plots (ensemble is visualized only once, so remaining 5 plots are disabled)\n",
    "        for i in range(1, 6):\n",
    "            axes[3, i].axis('off')\n",
    "\n",
    "        # Add colorbar (explicitly specify to avoid overlapping with other plots)\n",
    "        plt.subplots_adjust(right=0.85)  # Add space between plots and colorbar\n",
    "        cbar_ax = fig.add_axes([0.87, 0.15, 0.02, 0.7])  # Add colorbar to the right side of the plot\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "        cbar.set_label('Rainfall rate (mm/hr)', fontsize=16)\n",
    "\n",
    "        # Save the visualized result\n",
    "        output_path = os.path.join(save_dir, f\"{pred_image_name[b]}_visualization.png\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def test_ensemble_model_and_save_results(\n",
    "    models, test_data_path, device, amp_enabled, batch_size, save_dir, mode, weights\n",
    "):\n",
    "    \"\"\"\n",
    "    Save and visualize the results of ensemble models. Save the predictions and ground truth for each model.\n",
    "\n",
    "    Parameters:\n",
    "        models: List of models to be tested (ensemble models)\n",
    "        test_data_path: Path to the test dataset\n",
    "        device: Device to be used (CPU or GPU)\n",
    "        amp_enabled: Whether to use AMP (Automatic Mixed Precision)\n",
    "        batch_size: Batch size\n",
    "        save_dir: Base folder path to save the results\n",
    "        mode: Ensemble method (arithmetic, geometric, harmonic)\n",
    "        weights: List of ensemble weights\n",
    "    \"\"\"\n",
    "    # Load the test dataset\n",
    "    test_set = TSDataset(Path(test_data_path), transform=ToTensor())\n",
    "    loader_args = dict(batch_size=batch_size,\n",
    "                       num_workers=min(4, os.cpu_count() // 2),\n",
    "                       pin_memory=(device.type == 'cuda'))\n",
    "    test_loader = DataLoader(test_set, shuffle=False, drop_last=False, **loader_args)\n",
    "\n",
    "    # Generate ensemble identifier (mode, weights, datetime)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    ensemble_id = f\"{mode}_weights_{'_'.join(map(str, weights))}_{timestamp}\"\n",
    "\n",
    "    # Create folder structure\n",
    "    inputs_dir = os.path.join(save_dir, 'inputs')\n",
    "    model_outputs_dir = os.path.join(save_dir, 'model_outputs')\n",
    "    labels_dir = os.path.join(save_dir, 'labels')\n",
    "    ensemble_predictions_dir = os.path.join(save_dir, 'ensemble_predictions', ensemble_id)\n",
    "    visualizations_dir = os.path.join(save_dir, 'visualizations', ensemble_id)  # Add path to save visualizations\n",
    "    os.makedirs(inputs_dir, exist_ok=True)\n",
    "    os.makedirs(model_outputs_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    os.makedirs(ensemble_predictions_dir, exist_ok=True)\n",
    "    os.makedirs(visualizations_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing Ensemble\", unit=\"batch\"):\n",
    "            inputs, targets = batch['input'], batch['label']\n",
    "            input_names = batch['input_names']  # List of original input image filenames\n",
    "            label_names = batch['label_names']  # List of original target image filenames\n",
    "\n",
    "            inputs = inputs.to(device=device, dtype=torch.float32)\n",
    "            targets = targets.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # List to store outputs of each model\n",
    "            model_outputs = []\n",
    "\n",
    "            # Save predictions for each model\n",
    "            for model_idx, model in enumerate(models):\n",
    "                with torch.amp.autocast('cuda', enabled=amp_enabled):\n",
    "                    model_output = model(inputs)  # Model output\n",
    "                    model_outputs.append(model_output)\n",
    "\n",
    "            # Calculate ensemble results (arithmetic, geometric, harmonic mean)\n",
    "            weight_sum = sum(weights)\n",
    "            if mode == 'arithmetic':\n",
    "                weighted_outputs = [w * output for w, output in zip(weights, model_outputs)]\n",
    "                ensemble_predictions = torch.sum(torch.stack(weighted_outputs, dim=0), dim=0) / weight_sum\n",
    "            elif mode == 'geometric':\n",
    "                weighted_outputs = [output ** w for w, output in zip(weights, model_outputs)]\n",
    "                product = torch.prod(torch.stack(weighted_outputs, dim=0), dim=0)\n",
    "                ensemble_predictions = product ** (1 / weight_sum)\n",
    "            elif mode == 'harmonic':\n",
    "                reciprocal_sum = torch.zeros_like(model_outputs[0])\n",
    "                for w, output in zip(weights, model_outputs):\n",
    "                    reciprocal_sum += w / output\n",
    "                ensemble_predictions = weight_sum / reciprocal_sum\n",
    "\n",
    "            # Visualize and save results\n",
    "            visualize_and_save(inputs, targets, model_outputs, ensemble_predictions, input_names, input_names[0], visualizations_dir)\n",
    "\n",
    "    print(f\"Ensemble results saved in {save_dir}\")\n",
    "\n",
    "\n",
    "# Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # Set device to GPU if available, else CPU\n",
    "amp = False  # AMP (Automatic Mixed Precision) disabled\n",
    "batch_size = 4  # Batch size for data loading\n",
    "save_dir = '/home/sehoon/Desktop/측량학회/visualization'  # Directory to save the results\n",
    "test_data_path = \"/home/sehoon/Desktop/측량학회/data/dataset_0.5_0.05_6_1_1/test/\"  # Path to the test dataset\n",
    "evaluater_seq_len = 1  # Sequence length for evaluator\n",
    "\n",
    "# Pre-trained model list and weight paths\n",
    "model_classes = [\n",
    "    UNet(n_channels=6, n_classes=1),\n",
    "    SEUNet(n_channels=6, n_classes=1),\n",
    "    AttUNet(n_channels=6, n_classes=1),\n",
    "    DualAttUNet(n_channels=6, n_classes=1)\n",
    "]\n",
    "model_paths = [\n",
    "    \"/home/sehoon/Desktop/측량학회/results/UNet_epochs=100_bs=4_lr=0.0001_20240922_173646_final_model.pth\",\n",
    "    \"/home/sehoon/Desktop/측량학회/results/SEUNet_epochs=100_bs=4_lr=0.0001_20240922_173701_final_model.pth\",\n",
    "    \"/home/sehoon/Desktop/측량학회/results/AttUNet_epochs=100_bs=4_lr=0.0001_20240922_162424_final_model.pth\",\n",
    "    \"/home/sehoon/Desktop/측량학회/results/DualAttUNet_epochs=100_bs=4_lr=0.0001_20240922_162419_final_model.pth\"\n",
    "]\n",
    "\n",
    "# Initialize the model list\n",
    "models = []\n",
    "\n",
    "# Load the complete model for each pre-trained model and move it to the GPU\n",
    "for model_class, model_path in zip(model_classes, model_paths):\n",
    "    model = torch.load(model_path, map_location=device)  # Load the complete model\n",
    "    model.to(device)  # Move model to GPU\n",
    "    models.append(model)  # Add the model instance to the list\n",
    "\n",
    "# Test data path and ensemble settings\n",
    "test_data_path = \"/home/sehoon/Desktop/측량학회/data/dataset_0.5_0.05_6_1_1/test/\"\n",
    "weights = [0.1, 0.5, 0.1, 0.3]  # Set ensemble weights\n",
    "mode = 'arithmetic'  # Ensemble method\n",
    "\n",
    "# Test and save ensemble results\n",
    "test_ensemble_model_and_save_results(\n",
    "    models=models,\n",
    "    test_data_path=test_data_path,\n",
    "    device=device,\n",
    "    amp_enabled=amp,\n",
    "    batch_size=batch_size,\n",
    "    save_dir=save_dir,\n",
    "    mode=mode,\n",
    "    weights=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2850879/2524884723.py:254: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  models[i] = torch.load(model_paths[i], map_location=device)  # 각 모델의 가중치를 로드\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with mode: arithmetic and weights: [0.1, 0.5, 0.1, 0.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Ensemble: 100%|██████████| 229/229 [00:12<00:00, 17.83batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     15044136 |      4711781 |      1226875 |       238806 |        11892\n",
      "INFO:root:      Precision |       0.9209 |       0.8531 |       0.7791 |       0.7391 |       0.7093\n",
      "INFO:root:         Recall |       0.9039 |       0.8765 |       0.8134 |       0.6651 |       0.4087\n",
      "INFO:root:       F1 Score |       0.9123 |       0.8646 |       0.7959 |       0.7001 |       0.5186\n",
      "INFO:root:            FAR |       0.0791 |       0.1469 |       0.2209 |       0.2609 |       0.2907\n",
      "INFO:root:            CSI |       0.8388 |       0.7615 |       0.6610 |       0.5386 |       0.3500\n",
      "INFO:root:            GSS |       0.7841 |       0.7407 |       0.6536 |       0.5366 |       0.3499\n",
      "INFO:root:            HSS |       0.8790 |       0.8511 |       0.7905 |       0.6984 |       0.5184\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |       0.0015\n",
      "INFO:root:            MAE |       0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0015\n",
      "Mean Absolute Error (MAE): 0.0078\n",
      "Ensemble results saved in /home/sehoon/Desktop/측량학회/ensemble/\n",
      "Testing with mode: geometric and weights: [0.1, 0.5, 0.1, 0.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Ensemble:   0%|          | 0/229 [00:00<?, ?batch/s]/tmp/ipykernel_2850879/2524884723.py:23: RuntimeWarning: invalid value encountered in cast\n",
      "  image = (image * 255).astype(np.uint8)  # 0-1 사이 값을 0-255 범위로 변환\n",
      "Testing Ensemble: 100%|██████████| 229/229 [00:12<00:00, 17.97batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     15037585 |      4709819 |      1226231 |       238581 |        11879\n",
      "INFO:root:      Precision |       0.9212 |       0.8534 |       0.7795 |       0.7396 |       0.7101\n",
      "INFO:root:         Recall |       0.9035 |       0.8761 |       0.8130 |       0.6645 |       0.4082\n",
      "INFO:root:       F1 Score |       0.9123 |       0.8646 |       0.7959 |       0.7000 |       0.5184\n",
      "INFO:root:            FAR |       0.0788 |       0.1466 |       0.2205 |       0.2604 |       0.2899\n",
      "INFO:root:            CSI |       0.8387 |       0.7615 |       0.6610 |       0.5385 |       0.3499\n",
      "INFO:root:            GSS |       0.7840 |       0.7407 |       0.6536 |       0.5365 |       0.3498\n",
      "INFO:root:            HSS |       0.8789 |       0.8511 |       0.7905 |       0.6983 |       0.5182\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |          nan\n",
      "INFO:root:            MAE |          nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): nan\n",
      "Mean Absolute Error (MAE): nan\n",
      "Ensemble results saved in /home/sehoon/Desktop/측량학회/ensemble/\n",
      "Testing with mode: harmonic and weights: [0.1, 0.5, 0.1, 0.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Ensemble: 100%|██████████| 229/229 [00:13<00:00, 17.40batch/s]\n",
      "INFO:root:         Metric |         >0.5 |         >2.0 |         >5.0 |        >10.0 |        >30.0\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:       TP Count |     15031527 |      4707963 |      1225533 |       238369 |        11863\n",
      "INFO:root:      Precision |       0.9212 |       0.8532 |       0.7782 |       0.7330 |       0.6128\n",
      "INFO:root:         Recall |       0.9032 |       0.8757 |       0.8125 |       0.6639 |       0.4077\n",
      "INFO:root:       F1 Score |       0.9121 |       0.8643 |       0.7950 |       0.6967 |       0.4896\n",
      "INFO:root:            FAR |       0.0788 |       0.1468 |       0.2218 |       0.2670 |       0.3872\n",
      "INFO:root:            CSI |       0.8384 |       0.7611 |       0.6598 |       0.5346 |       0.3242\n",
      "INFO:root:            GSS |       0.7836 |       0.7402 |       0.6523 |       0.5326 |       0.3240\n",
      "INFO:root:            HSS |       0.8787 |       0.8507 |       0.7896 |       0.6950 |       0.4894\n",
      "INFO:root:-----------------------------------------------------------------------------------------\n",
      "INFO:root:            MSE |       0.2307\n",
      "INFO:root:            MAE |       0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.2307\n",
      "Mean Absolute Error (MAE): 0.0081\n",
      "Ensemble results saved in /home/sehoon/Desktop/측량학회/ensemble/\n",
      "Grid search results saved in /home/sehoon/Desktop/측량학회/ensemble/ensemble_grid_search_results_.xlsx\n"
     ]
    }
   ],
   "source": [
    "def save_image(tensor, path):\n",
    "    \"\"\"\n",
    "    Function to save a tensor as an image.\n",
    "    \"\"\"\n",
    "    image = tensor.cpu().numpy()\n",
    "    image = np.squeeze(image)  # Remove the channel dimension\n",
    "    image = (image * 255).astype(np.uint8)  # Convert values from range 0-1 to 0-255\n",
    "    Image.fromarray(image).save(path)\n",
    "\n",
    "\n",
    "def test_ensemble_model_and_save_results(\n",
    "    models, test_data_path, device, amp_enabled, batch_size, save_dir, mode, weights, evaluater_seq_len\n",
    "):\n",
    "    \"\"\"\n",
    "    Save and visualize ensemble model results. Store predictions and evaluation metrics in numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - models: List of models to be tested (ensemble models)\n",
    "    - test_data_path: Path to the test dataset\n",
    "    - device: Device to be used (CPU or GPU)\n",
    "    - amp_enabled: Whether to use AMP (Automatic Mixed Precision)\n",
    "    - batch_size: Batch size for data loading\n",
    "    - save_dir: Base folder path to save the results\n",
    "    - mode: Ensemble method (arithmetic, geometric, harmonic)\n",
    "    - weights: List of ensemble weights\n",
    "    - evaluater_seq_len: Sequence length for performance evaluation\n",
    "\n",
    "    Returns:\n",
    "    - result_np: Numpy array containing performance metrics\n",
    "    - result_np_2: Numpy array containing MSE and MAE\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the test dataset\n",
    "    test_set = TSDataset(Path(test_data_path), transform=ToTensor())\n",
    "    loader_args = dict(batch_size=batch_size,\n",
    "                       num_workers=min(4, os.cpu_count() // 2),\n",
    "                       pin_memory=(device.type == 'cuda'))\n",
    "    test_loader = DataLoader(test_set, shuffle=False, drop_last=False, **loader_args)\n",
    "\n",
    "    # Initialize the Evaluater\n",
    "    evaluater = Evaluater(seq_len=evaluater_seq_len)\n",
    "\n",
    "    # Generate ensemble identifier (mode, weights, datetime)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    ensemble_id = f\"{mode}_weights_{'_'.join(map(str, weights))}_{timestamp}\"\n",
    "\n",
    "    # Create folder structure\n",
    "    inputs_dir = os.path.join(save_dir, 'inputs')\n",
    "    model_outputs_dir = os.path.join(save_dir, 'model_outputs')\n",
    "    labels_dir = os.path.join(save_dir, 'labels')\n",
    "    ensemble_predictions_dir = os.path.join(save_dir, 'ensemble_predictions', ensemble_id)\n",
    "    os.makedirs(inputs_dir, exist_ok=True)\n",
    "    os.makedirs(model_outputs_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    os.makedirs(ensemble_predictions_dir, exist_ok=True)\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing Ensemble\", unit=\"batch\"):\n",
    "            inputs, targets = batch['input'], batch['label']\n",
    "            input_names = batch['input_names']  # List of original input image filenames\n",
    "            label_names = batch['label_names']  # List of original target image filenames\n",
    "\n",
    "            inputs = inputs.to(device=device, dtype=torch.float32)\n",
    "            targets = targets.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # List to store outputs of each model\n",
    "            model_outputs = []\n",
    "\n",
    "            # Store predictions for each model\n",
    "            for model_idx, model in enumerate(models):\n",
    "                with torch.amp.autocast('cuda', enabled=amp_enabled):\n",
    "                    model_output = model(inputs)  # Model output\n",
    "                    model_outputs.append(model_output)\n",
    "\n",
    "            epsilon = 1e-10  # Small value to prevent division by zero\n",
    "            # Calculate ensemble results (arithmetic, geometric, harmonic mean)\n",
    "            weight_sum = sum(weights)\n",
    "            if mode == 'arithmetic':\n",
    "                weighted_outputs = [w * output for w, output in zip(weights, model_outputs)]\n",
    "                ensemble_predictions = torch.sum(torch.stack(weighted_outputs, dim=0), dim=0) / weight_sum\n",
    "            elif mode == 'geometric':\n",
    "                weighted_outputs = [(output + epsilon) ** w for w, output in zip(weights, model_outputs)]\n",
    "                product = torch.prod(torch.stack(weighted_outputs, dim=0), dim=0)\n",
    "                ensemble_predictions = product ** (1 / weight_sum)\n",
    "            elif mode == 'harmonic':\n",
    "                reciprocal_sum = torch.zeros_like(model_outputs[0])\n",
    "                for w, output in zip(weights, model_outputs):\n",
    "                    reciprocal_sum += w / (output + epsilon)  # Prevent division by zero\n",
    "                ensemble_predictions = weight_sum / reciprocal_sum\n",
    "\n",
    "            # Save ensemble prediction results\n",
    "            for i in range(ensemble_predictions.size(0)):  # Iterate over batch size\n",
    "                ensemble_image_name = input_names[0][i].split('.')[0]  # Use the first input image name\n",
    "                ensemble_image_path = os.path.join(ensemble_predictions_dir, f\"{ensemble_image_name}.png\")\n",
    "\n",
    "                # Create directories and save ensemble prediction images\n",
    "                os.makedirs(os.path.dirname(ensemble_image_path), exist_ok=True)\n",
    "                save_image(ensemble_predictions[i], ensemble_image_path)\n",
    "\n",
    "            # Update performance evaluation\n",
    "            evaluater.update(gt=targets.cpu().numpy(), pred=ensemble_predictions.cpu().numpy())\n",
    "\n",
    "        # Output and evaluate performance metrics\n",
    "        precision, recall, f1, far, csi, hss, gss, mse, mae = evaluater.print_stat_readable()\n",
    "\n",
    "        result_np = np.array([precision, recall, f1, far, csi, hss, gss])\n",
    "        result_np_2 = np.array([mse, mae])\n",
    "\n",
    "        # Print loss and evaluation results\n",
    "        print(f\"Mean Squared Error (MSE): {mse.mean():.4f}\")\n",
    "        print(f\"Mean Absolute Error (MAE): {mae.mean():.4f}\")\n",
    "        print(f\"Ensemble results saved in {save_dir}\")\n",
    "\n",
    "    return result_np, result_np_2\n",
    "\n",
    "\n",
    "def run_grid_search_and_save_results(models, test_data_path, device, amp_enabled, batch_size, save_dir, evaluater_seq_len):\n",
    "    \"\"\"\n",
    "    Sequentially test given weights and ensemble methods, then save the results in a multi-indexed Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - models: List of models to be tested (ensemble models)\n",
    "    - test_data_path: Path to the test dataset\n",
    "    - device: Device to be used (CPU or GPU)\n",
    "    - amp_enabled: Whether to use AMP (Automatic Mixed Precision)\n",
    "    - batch_size: Batch size for data loading\n",
    "    - save_dir: Base folder path to save the results\n",
    "    - evaluater_seq_len: Sequence length for Evaluater\n",
    "    \"\"\"\n",
    "    # Candidate weights and ensemble methods (30 weight combinations)\n",
    "    weight_candidates = [\n",
    "        [0.1, 0.5, 0.1, 0.3]\n",
    "    ]\n",
    "\n",
    "    mode_candidates = ['arithmetic', 'geometric', 'harmonic']\n",
    "\n",
    "    # Prepare a list to store data for saving\n",
    "    results_list = []\n",
    "\n",
    "    # Execute all combinations of weights and ensemble methods\n",
    "    for weights in weight_candidates:\n",
    "        for mode in mode_candidates:\n",
    "            print(f\"Testing with mode: {mode} and weights: {weights}\")\n",
    "\n",
    "            # Test ensemble results and return as numpy arrays\n",
    "            result_np1, result_np2 = test_ensemble_model_and_save_results(\n",
    "                models=models,\n",
    "                test_data_path=test_data_path,\n",
    "                device=device,\n",
    "                amp_enabled=amp_enabled,\n",
    "                batch_size=batch_size,\n",
    "                save_dir=save_dir,\n",
    "                mode=mode,\n",
    "                weights=weights,\n",
    "                evaluater_seq_len=evaluater_seq_len\n",
    "            )\n",
    "\n",
    "            # Process data for multi-index storage\n",
    "            ensemble_id = f\"{mode}_weights_{'_'.join(map(str, weights))}\"\n",
    "            thresholds = [0.5, 2, 5, 10, 30]\n",
    "            thresholds_str = [f'>{threshold}' for threshold in thresholds]\n",
    "            metrics_names = ['Precision', 'Recall', 'F1 Score', 'FAR', 'CSI', 'HSS', 'GSS']\n",
    "            mse_mae_names = ['MSE', 'MAE']\n",
    "\n",
    "            # Process data for each metric (result_np1)\n",
    "            for metric_idx, metric_name in enumerate(metrics_names):\n",
    "                for threshold_idx, threshold in enumerate(thresholds_str):\n",
    "                    results_list.append({\n",
    "                        'Ensemble': ensemble_id,\n",
    "                        'Metric': metric_name,\n",
    "                        'Threshold': threshold,\n",
    "                        'Value': result_np1[metric_idx, 0, threshold_idx]\n",
    "                    })\n",
    "\n",
    "            # Add data for MSE and MAE (result_np2)\n",
    "            for mse_mae_idx, mse_mae_name in enumerate(mse_mae_names):\n",
    "                for threshold_idx, threshold in enumerate(thresholds_str):\n",
    "                    results_list.append({\n",
    "                        'Ensemble': ensemble_id,\n",
    "                        'Metric': mse_mae_name,\n",
    "                        'Threshold': threshold,\n",
    "                        'Value': result_np2[mse_mae_idx, 0]\n",
    "                    })\n",
    "\n",
    "    # Convert list to pandas DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Create multi-index and save to Excel file\n",
    "    results_df.set_index(['Ensemble', 'Metric', 'Threshold'], inplace=True)\n",
    "    xlsx_save_path = os.path.join(save_dir, \"ensemble_grid_search_results_.xlsx\")\n",
    "    results_df.to_excel(xlsx_save_path)\n",
    "\n",
    "    print(f\"Grid search results saved in {xlsx_save_path}\")\n",
    "\n",
    "\n",
    "# Example: Execute Grid Search\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "amp = False\n",
    "batch_size = 4\n",
    "save_dir = '/home/sehoon/Desktop/측량학회/ensemble/'  # Base folder to save results\n",
    "test_data_path = \"/home/sehoon/Desktop/측량학회/data/dataset_0.5_0.05_6_1_1/test/\"\n",
    "evaluater_seq_len = 1\n",
    "\n",
    "# Load pre-trained models\n",
    "models = [\n",
    "    UNet(n_channels=6, n_classes=1),\n",
    "    SEUNet(n_channels=6, n_classes=1),\n",
    "    AttUNet(n_channels=6, n_classes=1),\n",
    "    DualAttUNet(n_channels=6, n_classes=1)\n",
    "]\n",
    "\n",
    "# Load pre-trained model weights (weight file paths required)\n",
    "model_paths = [\n",
    "    \"/home/sehoon/Desktop/측량학회/results/UNet_epochs=100_bs=4_lr=0.0001_20240922_173646_final_model.pth\",\n",
    "    \"/home/sehoon/Desktop/측량학회/results/SEUNet_epochs=100_bs=4_lr=0.0001_20240922_173701_final_model.pth\",\n",
    "    \"/home/sehoon/Desktop/측량학회/results/AttUNet_epochs=100_bs=4_lr=0.0001_20240922_162424_final_model.pth\",\n",
    "    \"/home/sehoon/Desktop/측량학회/results/DualAttUNet_epochs=100_bs=4_lr=0.0001_20240922_162419_final_model.pth\"\n",
    "]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    models[i] = torch.load(model_paths[i], map_location=device)  # Load weights for each model\n",
    "    models[i].to(device)  # Move models to GPU\n",
    "\n",
    "# Execute Grid Search\n",
    "run_grid_search_and_save_results(\n",
    "    models=models,\n",
    "    test_data_path=test_data_path,\n",
    "    device=device,\n",
    "    amp_enabled=amp,\n",
    "    batch_size=batch_size,\n",
    "    save_dir=save_dir,\n",
    "    evaluater_seq_len=evaluater_seq_len\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainfall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
